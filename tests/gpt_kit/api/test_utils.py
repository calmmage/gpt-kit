from gpt_kit.api.utils import get_token_count_estimate, _get_token_count
import pytest

queries = [
    ("This is a test. Write a fun poem about spinning tops:", 16, 13),
    ("Ð ÑƒÑÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚. Write a fun poem about spinning tops:", 28, 24),
    ("User1, user2, 6749589, pep, Ð ÑƒÑÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚. "
     "Write a fun poem about spinning tops:", 45, 37),
    ("Emojis: ðŸ¤”, âœ…, ??, ??", 18, 15),
    ("Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼, Ñ‡Ñ‚Ð¾ Ð±ÑƒÐ´ÐµÑ‚, ÐµÑÐ»Ð¸ Ð¼Ñ‹ Ð²Ð²ÐµÐ´ÐµÐ¼ Ñ€ÑƒÑÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚", 63, 62),
    ("",  0, 0),
    ("12",  2, 1),
    ("a",  1, 1),
    ("user",  1, 1),
    ("1", 1, 1),
    ("Ñ†", 2, 2),
    ("Ñ", 2, 1),
]
@pytest.mark.parametrize("text,est,real", queries)
def test_get_token_count(text,est,real):
    estimate = get_token_count_estimate(text)
    token_count = _get_token_count(text)
    assert token_count == real
    assert estimate == est
    assert estimate >= token_count

# todo: test parse_model

# todo: test get_model_token_limit
